{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file with company names and urls. Name columns appropriately and drop what is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = find('AllUrls.csv', 'C://')\n",
    "urls = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary columns and give the remaining columns appropriate names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = urls.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 6', 'Unnamed: 7'])\n",
    "urls = urls.rename(columns={'Unnamed: 4':'Target URL', 'Unnamed: 8':'Acquiror URL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Effective</th>\n",
       "      <th>Target Name</th>\n",
       "      <th>Target URL</th>\n",
       "      <th>Acquiror Name</th>\n",
       "      <th>Acquiror URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/12/2017 00:00</td>\n",
       "      <td>Netrisk.hu</td>\n",
       "      <td>netrisk.hu</td>\n",
       "      <td>MCI EuroVentures 1 0</td>\n",
       "      <td>https://mci.pl/en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/12/2017 00:00</td>\n",
       "      <td>Health Integrated Inc</td>\n",
       "      <td>healthintegrated.com</td>\n",
       "      <td>ExlService Holdings Inc</td>\n",
       "      <td>https://www.exlservice.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21/12/2017 00:00</td>\n",
       "      <td>HealthSun Health Plans Inc</td>\n",
       "      <td>healthsun.com</td>\n",
       "      <td>Anthem Inc</td>\n",
       "      <td>anthem.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/12/2017 00:00</td>\n",
       "      <td>Brighter Inc</td>\n",
       "      <td>https://providers.brighter.com/</td>\n",
       "      <td>Cigna Corp</td>\n",
       "      <td>cigna.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/12/2017 00:00</td>\n",
       "      <td>EC Insurance Co Ltd</td>\n",
       "      <td>https://www.ecic.co.uk/</td>\n",
       "      <td>Markel Intl Ins Co Ltd</td>\n",
       "      <td>http://www.markelinternational.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date Effective                 Target Name  \\\n",
       "0  29/12/2017 00:00                  Netrisk.hu   \n",
       "1  26/12/2017 00:00       Health Integrated Inc   \n",
       "2  21/12/2017 00:00  HealthSun Health Plans Inc   \n",
       "3  14/12/2017 00:00                Brighter Inc   \n",
       "4  04/12/2017 00:00         EC Insurance Co Ltd   \n",
       "\n",
       "                        Target URL            Acquiror Name  \\\n",
       "0                       netrisk.hu     MCI EuroVentures 1 0   \n",
       "1             healthintegrated.com  ExlService Holdings Inc   \n",
       "2                    healthsun.com               Anthem Inc   \n",
       "3  https://providers.brighter.com/               Cigna Corp   \n",
       "4          https://www.ecic.co.uk/   Markel Intl Ins Co Ltd   \n",
       "\n",
       "                          Acquiror URL  \n",
       "0                    https://mci.pl/en  \n",
       "1          https://www.exlservice.com/  \n",
       "2                           anthem.com  \n",
       "3                            cigna.com  \n",
       "4  http://www.markelinternational.com/  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill empty values and errors with 'None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = urls.fillna(value='None')\n",
    "urls = urls.replace(to_replace='#ERROR!', value='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls['Date Effective'] = pd.to_datetime(urls['Date Effective'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all urls in the form http(s)://....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in urls.iterrows():\n",
    "    if urls.iloc[index]['Target URL'] != 'None':\n",
    "        if (urls.iloc[index]['Target URL'].startswith('http')==False):\n",
    "            new_url = 'https://' + urls.iloc[index]['Target URL']\n",
    "            urls.at[index, 'Target URL'] = new_url\n",
    "        if ('www' not in '/'.join(urls.iloc[index]['Target URL'].split('/', 2)[-1:])) and (urls.iloc[index]['Target URL'] != 'None'):\n",
    "            new_url = 'https://www.'+'/'.join(urls.iloc[index]['Target URL'].split('/',2)[2:])\n",
    "            urls.at[index, 'Target URL'] = new_url\n",
    "    if urls.iloc[index]['Acquiror URL'] != 'None':\n",
    "        if (urls.iloc[index]['Acquiror URL'].startswith('http')==False):\n",
    "            new_url = 'https://' + urls.iloc[index]['Acquiror URL']\n",
    "            urls.at[index, 'Acquiror URL'] = new_url\n",
    "        if ('www' not in '/'.join(urls.iloc[index]['Acquiror URL'].split('/', 2)[-1:])):\n",
    "            new_url = 'https://www.'+'/'.join(urls.iloc[index]['Acquiror URL'].split('/',2)[2:])\n",
    "            urls.at[index, 'Acquiror URL'] = new_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add columns for the URLs before and after the date effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls['Target one week prior'] =\"\"\n",
    "urls['Acquiror one week prior'] =\"\"\n",
    "urls['Target two years after'] =\"\"\n",
    "urls['Acquiror two years after'] =\"\"\n",
    "urls['Target URL one week prior']=\"\"\n",
    "urls['Acquiror URL one week prior']= \"\"\n",
    "urls['Target URL two years after'] = \"\"\n",
    "urls['Acquiror URL two years after']= \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file in which all the URLs before the date effective are stored. This is the URL + the date one week before the date effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('C:/URLSBefore.txt', 'w') \n",
    "\n",
    "for index, row in urls.iterrows():\n",
    "    date_effective = urls.iloc[index]['Date Effective'].date()\n",
    "    date_one_week_prior = date_effective + relativedelta(weeks=-1)\n",
    "    date_one_week_prior = str(date_one_week_prior).replace('-',\"\")\n",
    "    \n",
    "    if urls.iloc[index]['Target URL'] != 'None':\n",
    "        target_address_one_week_prior = 'https://web.archive.org/web/' + date_one_week_prior  +'/'+ urls.iloc[index]['Target URL']\n",
    "        urls.at[index, 'Target one week prior'] = date_one_week_prior\n",
    "        urls.at[index, 'Target URL one week prior'] = target_address_one_week_prior\n",
    "        file.write(target_address_one_week_prior+ '\\n')\n",
    "    if urls.iloc[index]['Acquiror URL'] != 'None':\n",
    "        acquiror_address_one_week_prior = 'https://web.archive.org/web/' + date_one_week_prior  +'/'+ urls.iloc[index]['Acquiror URL'] \n",
    "        urls.at[index, 'Acquiror one week prior'] = date_one_week_prior\n",
    "        urls.at[index, 'Acquiror URL one week prior'] = acquiror_address_one_week_prior\n",
    "        file.write(acquiror_address_one_week_prior+ '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file in which all the URLs after the date effective are stored. This the URL + the date two years after the date effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('C:/URLSAfter.txt', 'w') \n",
    "\n",
    "for index, row in urls.iterrows():\n",
    "    date_effective = urls.iloc[index]['Date Effective'].date()\n",
    "    date_two_years_after = date_effective + relativedelta(years=+2)\n",
    "    date_two_years_after = str(date_two_years_after).replace('-',\"\")\n",
    "   \n",
    "    if urls.iloc[index]['Target URL'] != 'None':\n",
    "        target_address_two_years_after = 'https://web.archive.org/web/' + date_two_years_after  +'/'+ urls.iloc[index]['Target URL']\n",
    "        urls.at[index, 'Target two years after'] = date_two_years_after\n",
    "        urls.at[index, 'Target URL two years after']  = target_address_two_years_after\n",
    "        file.write(target_address_two_years_after+ '\\n')\n",
    "    if urls.iloc[index]['Acquiror URL'] != 'None':\n",
    "        acquiror_address_two_years_after = 'https://web.archive.org/web/' + date_two_years_after  +'/'+ urls.iloc[index]['Acquiror URL'] \n",
    "        urls.at[index, 'Acquiror two years after'] = date_two_years_after\n",
    "        urls.at[index, 'Acquiror URL two years after'] = acquiror_address_two_years_after\n",
    "        file.write(acquiror_address_two_years_after+ '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the date string to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls['Date Effective']=urls['Date Effective'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the URL data to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls.to_excel('C:/CompanyUrls.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
