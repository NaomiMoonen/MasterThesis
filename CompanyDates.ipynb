{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from Levenshtein import ratio, distance\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the the deal data and URL data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = find('hmspall.xlsx', 'C://')\n",
    "transdata = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = find('AllUrls.csv', 'C://')\n",
    "allurls = pd.read_csv(path)\n",
    "allurls['Date Effective'] = pd.to_datetime(allurls['Date Effective'], format='%d/%m/%Y %H:%M')\n",
    "allurls = allurls[allurls['Date Effective']<'2018-01-01']\n",
    "allurls = allurls.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "allurls = allurls.rename(columns={'Unnamed: 4':'Target URL','Unnamed: 8':'Acquiror URL'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the company names and find the effective date that belongs to the companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets =list(transdata['Target Name'])\n",
    "acquirors = list(transdata['Acquiror Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "double = list()\n",
    "for index, row in allurls.iterrows():\n",
    "    target = allurls.iloc[index]['Target Name']\n",
    "    acquiror = allurls.iloc[index]['Acquiror Name']\n",
    "    date = allurls.iloc[index]['Date Effective']\n",
    "    transdatasub=transdata[(transdata['Target Name']==target)&(transdata['Acquiror Name']==acquiror)&\n",
    "            (transdata['Date Effective']==date)]\n",
    "    if transdatasub.shape[0]>1:\n",
    "        double.append(index)\n",
    "\n",
    "    if distance(target, acquiror)==1:\n",
    "        double.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "allurls = allurls.drop(index=[308, 564])\n",
    "allurls = allurls.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "allurls['Target URL'] = allurls['Target URL'].fillna('None')\n",
    "allurls['Acquiror URL'] = allurls['Acquiror URL'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a URL is available and make them all in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in allurls.iterrows():\n",
    "    if allurls.iloc[index]['Target URL'] != 'None':\n",
    "        if (allurls.iloc[index]['Target URL'].startswith('http')==False):\n",
    "            new_url = 'https://' + allurls.iloc[index]['Target URL']\n",
    "            allurls.at[index, 'Target URL'] = new_url\n",
    "        if ('www' not in '/'.join(allurls.iloc[index]['Target URL'].split('/', 2)[-1:])) and (allurls.iloc[index]['Target URL'] != 'None'):\n",
    "            new_url = 'https://www.'+'/'.join(allurls.iloc[index]['Target URL'].split('/',2)[2:])\n",
    "            allurls.at[index, 'Target URL'] = new_url\n",
    "    if allurls.iloc[index]['Acquiror URL'] != 'None':\n",
    "        if (allurls.iloc[index]['Acquiror URL'].startswith('http')==False):\n",
    "            new_url = 'https://' + allurls.iloc[index]['Acquiror URL']\n",
    "            allurls.at[index, 'Acquiror URL'] = new_url\n",
    "        if ('www' not in '/'.join(allurls.iloc[index]['Acquiror URL'].split('/', 2)[-1:])):\n",
    "            new_url = 'https://www.'+'/'.join(allurls.iloc[index]['Acquiror URL'].split('/',2)[2:])\n",
    "            allurls.at[index, 'Acquiror URL'] = new_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date Effective', 'Target Name', 'Unnamed: 2', 'Unnamed: 3',\n",
       "       'Target URL', 'Acquiror Name', 'Unnamed: 6', 'Unnamed: 7',\n",
       "       'Acquiror URL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allurls.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe that summarizes the name and date information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "companydates = pd.DataFrame(columns=['Date Effective', 'Target Name', 'Target URL',\n",
    "                               'Target Companydate Before', 'Target Companydate After',\n",
    "                               'Acquiror Name', 'Acquiror URL',\n",
    "                              'Acquiror Companydate Before', 'Acquiror Companydate After'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in allurls.iterrows():\n",
    "    targeturl = row['Target URL']\n",
    "    acquirorurl = row['Acquiror URL']\n",
    "    target = row['Target Name']\n",
    "    acquiror = row['Acquiror Name']\n",
    "   \n",
    "    date_effective = row['Date Effective']\n",
    "    date_one_week_prior = date_effective + relativedelta(weeks=-1)\n",
    "    date_one_week_prior = str(date_one_week_prior).replace('-',\"\")[:-9]\n",
    "    date_two_years_after = date_effective + relativedelta(years=+2)\n",
    "    date_two_years_after = str(date_two_years_after).replace('-',\"\")[:-9]\n",
    "    targetfromurl = '/'.join(targeturl.split('.',2)[1:2])\n",
    "    acquirorfromurl = '/'.join(acquirorurl.split('.',2)[1:2])\n",
    "    if (targeturl != 'None') and (acquirorurl !='None'):\n",
    "        targetbefore = targetfromurl + date_one_week_prior\n",
    "        targetafter = targetfromurl +date_two_years_after\n",
    "        acquirorbefore = acquirorfromurl +date_one_week_prior\n",
    "        acquirorafter = acquirorfromurl +date_two_years_after\n",
    "        companydates = companydates.append({'Date Effective':date_effective, 'Target Name':targetfromurl, \n",
    "                            'Target URL':targeturl,'Target Companydate Before':targetbefore, \n",
    "                            'Target Companydate After':targetafter,'Acquiror Name':acquirorfromurl, \n",
    "                            'Acquiror URL':acquirorurl,'Acquiror Companydate Before':acquirorbefore, \n",
    "                            'Acquiror Companydate After':acquirorafter}, ignore_index=True)\n",
    "    elif (targeturl != 'None') and (acquirorurl == 'None'):\n",
    "        targetbefore = targetfromurl + date_one_week_prior\n",
    "        targetafter = targetfromurl +date_two_years_after\n",
    "        companydates = companydates.append({'Date Effective':date_effective, 'Target Name':targetfromurl, \n",
    "                            'Target URL':targeturl,'Target Companydate Before':targetbefore, \n",
    "                            'Target Companydate After':targetafter,'Acquiror Name':acquiror, \n",
    "                            'Acquiror URL':'None','Acquiror Companydate Before':'None', \n",
    "                            'Acquiror Companydate After':'None'}, ignore_index=True)\n",
    "    elif (targeturl == 'None') and (acquirorurl !='None'):\n",
    "        acquirorbefore = acquirorfromurl +date_one_week_prior\n",
    "        acquirorafter = acquirorfromurl +date_two_years_after\n",
    "        companydates = companydates.append({'Date Effective':date_effective, 'Target Name':target, \n",
    "                            'Target URL':'None','Target Companydate Before':'None', \n",
    "                            'Target Companydate After':'None','Acquiror Name':acquirorfromurl, \n",
    "                            'Acquiror URL':acquirorurl,'Acquiror Companydate Before':acquirorbefore, \n",
    "                            'Acquiror Companydate After':acquirorafter}, ignore_index=True)\n",
    "    elif (targeturl == 'None') and (acquirorurl =='None'):\n",
    "        companydates = companydates.append({'Date Effective':date_effective, 'Target Name':target, \n",
    "                            'Target URL':'None','Target Companydate Before':'None', \n",
    "                            'Target Companydate After':'None','Acquiror Name':acquiror, \n",
    "                            'Acquiror URL':'None','Acquiror Companydate Before':'None', \n",
    "                            'Acquiror Companydate After':'None'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "companydates.to_excel('C://AllCompanyDates.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
