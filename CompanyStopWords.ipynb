{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import pprint\n",
    "import csv\n",
    "from nltk.corpus import words\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the names of the target and acquiror companies from the deal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = find('dealdata.xlsx', 'C:/')\n",
    "data = pd.read_excel(path)\n",
    "targets = data['Target Name']\n",
    "targets = list(targets)\n",
    "acquirors = data['Acquiror Name']\n",
    "acquirors = list(acquirors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the target and acquiror names lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [t.lower() for t in targets]\n",
    "acquirors = [a.lower() for a in acquirors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words in the names of targets and acquirors that are no English vocabulary words are also added to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words = list()\n",
    "for target in targets:\n",
    "    fullname = target.split()\n",
    "    for name in fullname:        \n",
    "        if name.lower() not in words.words():\n",
    "            extra_words.append(name.lower())\n",
    "for acquiror in acquirors:\n",
    "    fullname = acquiror.split()\n",
    "    for name in fullname:\n",
    "        if name not in words.words():\n",
    "            extra_words.append(name.lower())\n",
    "extra_words = list(set(extra_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the extra words to verify that these are words that can be added as stop words. Otherwise add them to a wrong words list. Also add word parts to the extra words if they were not split properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_words=['activities','advisors','america','american','americas','asia','asia-pacific','associates',\n",
    "             'assurances','australian','austria','baltic','baptist','beaches','benefits','benelux','brasil',\n",
    "             'brokers','builders','cambridge','centre','clients','clinique','concepts','contacts','cooperative',\n",
    "             'coordinators','customcare','database','diagnostics',\"doctors'\",'doctors','eldercare','focused',\n",
    "             'fond','foods','gates','georgia','hawaii','healthcare','impuls','info','initiatives','integrated',\n",
    "             'investments','labs','london','madrid','managed','manufacturing','med','medicaid','mega',\n",
    "             'mid-atlantic','midwest','multiplan','munich','musculoskeletal','networks','ohio','online',\n",
    "             'operations','options','orleans','orthodontists','partners','peoples','physician','physicians',\n",
    "             'planning','plans','points','portugal','professionals','protocols','providers','purchasing',\n",
    "             'resources','scandinavian','schleswig-holstein','scripts','services','software','solutions',\n",
    "             'strategies','systems','technologies','uk', 'underwriters','workers','zuricht','holdings','everyone',\n",
    "            'africa','texas','russian','nyc','singapore','california','missouri','traders','claims','detroit',\n",
    "             'bermuda','irish','european','argentina','investors','europe','hospitalist','acquiror','spain',\n",
    "            'pro-claim','luxembourg','ventures','harvard','australia','communications']\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the extra words that are not wrong and not in the stop word list yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words = [i for i in extra_words if (i not in wrong_words) and (i not in stopwords)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add days of the week and months as stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(['monday','tuesday','wednesday','thursday','friday','saturday','sunday',\n",
    "                      'mon','mon.','tu.','tu','tue','tue.','tues','tues.','wed','wed.','th','th.','thu','thu.',\n",
    "                      'thur','thur.','thurs','thurs.','fri','fri.','sat','sat.','sun','sun.',\n",
    "                      'january','jan','jan.','february','feb','feb.','march','mar','mar.',\n",
    "                      'april','apr','apr.','may','june','july','august','aug','aug.','september',\n",
    "                      'sept','sept.','october','oct','oct.','november','nov','nov.','december',\n",
    "                      'november','nov','nov.','december','dec','dec.','juni','juli','a','b','c','d','e','f','g',\n",
    "                    'h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z'])\n",
    "stopwords = list(set(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the extra words to the stop list. Then, only keep words that are of type string, not decimal and convert everything to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(extra_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep strings that are not numbers and convert the strings to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [w for w in stopwords if type(w)==str]\n",
    "stopwords = [w for w in stopwords if not w.isdecimal()]\n",
    "stopwords = [i.lower() for i in stopwords]\n",
    "stopwords = list(set(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.DataFrame(data=stopwords,columns=['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the stopwords to an Excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.to_excel('customstopwords.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
